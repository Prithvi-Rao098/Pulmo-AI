{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b130f7-04db-4504-95fa-0dba7718c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnosis of lung damage based on medical imagery\n",
    "# dataset, model and training based on https://www.kaggle.com/code/fareedalianwar/chest-ctscan-pytorch-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a74db76a-46f6-40da-b2f9-8dfa4076a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/workbench/.local/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/workbench/.local/lib/python3.10/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/workbench/.local/lib/python3.10/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/workbench/.local/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/workbench/.local/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/workbench/.local/lib/python3.10/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/workbench/.local/lib/python3.10/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/workbench/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/workbench/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/workbench/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/workbench/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/workbench/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/workbench/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python-headless in /home/workbench/.local/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/workbench/.local/lib/python3.10/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/workbench/.local/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: fsspec in /home/workbench/.local/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: filelock in /home/workbench/.local/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in /home/workbench/.local/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: sympy in /home/workbench/.local/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/workbench/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /home/workbench/.local/lib/python3.10/site-packages (0.19.1)\n",
      "Requirement already satisfied: numpy in /home/workbench/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.4.1 in /home/workbench/.local/lib/python3.10/site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/workbench/.local/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: networkx in /home/workbench/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (3.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/workbench/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/workbench/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (2024.9.0)\n",
      "Requirement already satisfied: filelock in /home/workbench/.local/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/workbench/.local/lib/python3.10/site-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchinfo in /home/workbench/.local/lib/python3.10/site-packages (1.8.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in /home/workbench/.local/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.13.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/workbench/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/workbench/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.17.2)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.41)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.10)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# install necessary models, datasets, and libraries\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install opencv-python-headless\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install torchinfo\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c326da0-a776-409c-8bb9-f438c28c384a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.optim import lr_scheduler\n",
    "from torchinfo import summary\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "resnet18_model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68f121cd-8743-4b52-9c57-eff8946b6507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93192ea1-2b5e-438e-9f09-874b39f56760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to tensor\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "     transforms.RandomHorizontalFlip(p=0.7),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56485f25-14e0-4c14-bede-dd197f8dadbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613, 72)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring in the already imported data from the data directory\n",
    "import os\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data_path = '../data/ctimages/Data/train'\n",
    "test_data_path = '../data/ctimages/Data/valid'\n",
    "validation_data_path = '../data/ctimages/Data/valid'\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_data_path, transform=data_transform)\n",
    "test_data = datasets.ImageFolder(root=test_data_path, transform=data_transform)\n",
    "validation_data = datasets.ImageFolder(root=validation_data_path, transform=data_transform)\n",
    "\n",
    "len(train_data)  , len(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "554b0742-9e61-4f90-b632-7e91be0b8e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names: ['adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib', 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa', 'normal', 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa']\n",
      "Class Dictionary: {'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib': 0, 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa': 1, 'normal': 2, 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa': 3}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the list of class names and the dictionary mapping class names to their indices\n",
    "class_names = train_data.classes\n",
    "class_dict = train_data.class_to_idx\n",
    "\n",
    "# Output the class names and the class dictionary\n",
    "print(\"Class Names:\", class_names)\n",
    "print(\"Class Dictionary:\", class_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68593008-e48f-4bd4-b6d4-c8480ed83ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': 2, 'adenocarcinoma_left.lower.lobe': 0, 'large.cell.carcinoma_left.hilum': 1, 'squamous.cell.carcinoma_left.hilum': 3} 4\n"
     ]
    }
   ],
   "source": [
    "# Key mapping from old to new\n",
    "key_updates = {\n",
    "    'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib': 'adenocarcinoma_left.lower.lobe',\n",
    "    'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa': 'large.cell.carcinoma_left.hilum',\n",
    "    'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa': 'squamous.cell.carcinoma_left.hilum'\n",
    "}\n",
    "\n",
    "# Update the dictionary\n",
    "for old_key, new_key in key_updates.items():\n",
    "    if old_key in class_dict:\n",
    "        class_dict[new_key] = class_dict.pop(old_key)\n",
    "\n",
    "# Define new keys corresponding to their simplified names\n",
    "new_key1 = 'adenocarcinoma_left.lower.lobe'\n",
    "new_key2 = 'large.cell.carcinoma_left.hilum'\n",
    "new_key3 = 'squamous.cell.carcinoma_left.hilum'\n",
    "\n",
    "# Update specific indices in the class_names list\n",
    "class_names[0] = new_key1\n",
    "class_names[1] = new_key2\n",
    "class_names[3] = new_key3 \n",
    "\n",
    "print(class_dict, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "844711ae-8025-4191-aec2-f52ac2ddfb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (1): Dropout(p=0.2, inplace=False)\n",
       "  (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (3): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the model\n",
    "resnet18_model.fc = nn.Sequential (\n",
    "    nn.Linear(512,512),\n",
    "    nn.Dropout(0.2),\n",
    "     nn.Linear(512,256),\n",
    "    nn.Linear(256,len(class_names)), # -> len(labels) labels according to labels\n",
    ")\n",
    "resnet18_model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15830e5d-1003-4fe2-b5f8-9b609f2a902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_model.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30890b64-cbcf-4b93-87ab-10955aff3313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 4]                    --\n",
       "├─Conv2d: 1-1                            [1, 64, 32, 32]           9,408\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 32, 32]           128\n",
       "├─ReLU: 1-3                              [1, 64, 32, 32]           --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 16, 16]           --\n",
       "├─Sequential: 1-5                        [1, 64, 16, 16]           --\n",
       "│    └─BasicBlock: 2-1                   [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 16, 16]           36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 16, 16]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 16, 16]           --\n",
       "│    └─BasicBlock: 2-2                   [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 64, 16, 16]           36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-9                    [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 16, 16]           36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-12                   [1, 64, 16, 16]           --\n",
       "├─Sequential: 1-6                        [1, 128, 8, 8]            --\n",
       "│    └─BasicBlock: 2-3                   [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-13                 [1, 128, 8, 8]            73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 128, 8, 8]            256\n",
       "│    │    └─ReLU: 3-15                   [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-16                 [1, 128, 8, 8]            147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 128, 8, 8]            256\n",
       "│    │    └─Sequential: 3-18             [1, 128, 8, 8]            8,448\n",
       "│    │    └─ReLU: 3-19                   [1, 128, 8, 8]            --\n",
       "│    └─BasicBlock: 2-4                   [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-20                 [1, 128, 8, 8]            147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [1, 128, 8, 8]            256\n",
       "│    │    └─ReLU: 3-22                   [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-23                 [1, 128, 8, 8]            147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [1, 128, 8, 8]            256\n",
       "│    │    └─ReLU: 3-25                   [1, 128, 8, 8]            --\n",
       "├─Sequential: 1-7                        [1, 256, 4, 4]            --\n",
       "│    └─BasicBlock: 2-5                   [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-26                 [1, 256, 4, 4]            294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 256, 4, 4]            512\n",
       "│    │    └─ReLU: 3-28                   [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-29                 [1, 256, 4, 4]            589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 256, 4, 4]            512\n",
       "│    │    └─Sequential: 3-31             [1, 256, 4, 4]            33,280\n",
       "│    │    └─ReLU: 3-32                   [1, 256, 4, 4]            --\n",
       "│    └─BasicBlock: 2-6                   [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-33                 [1, 256, 4, 4]            589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [1, 256, 4, 4]            512\n",
       "│    │    └─ReLU: 3-35                   [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-36                 [1, 256, 4, 4]            589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [1, 256, 4, 4]            512\n",
       "│    │    └─ReLU: 3-38                   [1, 256, 4, 4]            --\n",
       "├─Sequential: 1-8                        [1, 512, 2, 2]            --\n",
       "│    └─BasicBlock: 2-7                   [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-39                 [1, 512, 2, 2]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 512, 2, 2]            1,024\n",
       "│    │    └─ReLU: 3-41                   [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-42                 [1, 512, 2, 2]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [1, 512, 2, 2]            1,024\n",
       "│    │    └─Sequential: 3-44             [1, 512, 2, 2]            132,096\n",
       "│    │    └─ReLU: 3-45                   [1, 512, 2, 2]            --\n",
       "│    └─BasicBlock: 2-8                   [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-46                 [1, 512, 2, 2]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [1, 512, 2, 2]            1,024\n",
       "│    │    └─ReLU: 3-48                   [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-49                 [1, 512, 2, 2]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [1, 512, 2, 2]            1,024\n",
       "│    │    └─ReLU: 3-51                   [1, 512, 2, 2]            --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
       "├─Sequential: 1-10                       [1, 4]                    --\n",
       "│    └─Linear: 2-9                       [1, 512]                  262,656\n",
       "│    └─Dropout: 2-10                     [1, 512]                  --\n",
       "│    └─Linear: 2-11                      [1, 256]                  131,328\n",
       "│    └─Linear: 2-12                      [1, 4]                    1,028\n",
       "==========================================================================================\n",
       "Total params: 11,571,524\n",
       "Trainable params: 11,571,524\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 148.45\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 3.25\n",
       "Params size (MB): 46.29\n",
       "Estimated Total Size (MB): 49.59\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet18_model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.SGD(resnet18_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "summary(resnet18_model, input_size=[1, 3, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b6b0b20-f0c0-4b34-a92b-5a330c53b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer:torch.optim.Optimizer,\n",
    "               device=device):\n",
    "  model.train()\n",
    "\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    y_pred = model(X) \n",
    "\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss.item()\n",
    "\n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "  \n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracy metric\n",
    "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "    train_acc += (y_pred_class==y).sum().item()/len(y_pred)\n",
    "  \n",
    "  # Adjust metrics to get average loss and accuracy per batch\n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader) \n",
    "  return train_loss, train_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed5e3440-f599-475e-93d9-02f98a6aba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device=device):\n",
    "  model.eval()\n",
    "\n",
    "  test_loss, test_acc = 0,  0\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X, y) in enumerate(dataloader): \n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      test_pred_logits = model(X)\n",
    "\n",
    "     \n",
    "      loss = loss_fn(test_pred_logits, y)\n",
    "      test_loss += loss.item()\n",
    "\n",
    "    \n",
    "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch\n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df928df7-1d6c-42b3-b362-2a2339b8ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader,\n",
    "          test_dataloader,\n",
    "          optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5, \n",
    "          device=device):\n",
    "  \n",
    "  results = {\"train_loss\": [],\n",
    "             \"train_acc\": [],\n",
    "             \"test_loss\": [],\n",
    "             \"test_acc\": []}\n",
    "  \n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(model=model,\n",
    "                                       dataloader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       device=device)\n",
    "    test_loss, test_acc = test_step(model=model,\n",
    "                                    dataloader=test_dataloader,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    device=device)\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
    "\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_acc\"].append(train_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_acc\"].append(test_acc)\n",
    "  \n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb2b42ff-8eb5-47a5-a276-69c28832ecba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d9d0eb3d8345f49f00e1a9b6d34a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.9919 | Train acc: 0.5619 | Test loss: 1.7529 | Test acc: 0.4062\n",
      "Epoch: 1 | Train loss: 0.3979 | Train acc: 0.8422 | Test loss: 0.7745 | Test acc: 0.7396\n",
      "Epoch: 2 | Train loss: 0.2636 | Train acc: 0.9034 | Test loss: 0.9266 | Test acc: 0.6875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model_0_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresnet18_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     10\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     11\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     12\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m---> 15\u001b[0m   train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m   test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     21\u001b[0m                                   dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m     22\u001b[0m                                   loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m     23\u001b[0m                                   device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 24\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate accuracy metric\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 15\n",
    "\n",
    "model_0_results = train(model=resnet18_model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95910a87-1d38-47c1-8e42-9ac35d86a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet18_model.state_dict(), \"../models/ct_scan_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c4412-01e7-43de-a340-a08216a52b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b1b65-8656-41cf-9d83-880fa3d790d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
