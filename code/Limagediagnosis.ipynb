{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3b130f7-04db-4504-95fa-0dba7718c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnosis of lung damage based on medical imagery\n",
    "# dataset, model and training based on https://www.kaggle.com/code/fareedalianwar/chest-ctscan-pytorch-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c326da0-a776-409c-8bb9-f438c28c384a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.optim import lr_scheduler\n",
    "from torchinfo import summary\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "resnet18_model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68f121cd-8743-4b52-9c57-eff8946b6507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93192ea1-2b5e-438e-9f09-874b39f56760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to tensor\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "     transforms.RandomHorizontalFlip(p=0.7),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56485f25-14e0-4c14-bede-dd197f8dadbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613, 72)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring in the already imported data from the data directory\n",
    "import os\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data_path = '../data/ctimages/Data/train'\n",
    "test_data_path = '../data/ctimages/Data/valid'\n",
    "validation_data_path = '../data/ctimages/Data/valid'\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_data_path, transform=data_transform)\n",
    "test_data = datasets.ImageFolder(root=test_data_path, transform=data_transform)\n",
    "validation_data = datasets.ImageFolder(root=validation_data_path, transform=data_transform)\n",
    "\n",
    "len(train_data)  , len(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "554b0742-9e61-4f90-b632-7e91be0b8e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names: ['adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib', 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa', 'normal', 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa']\n",
      "Class Dictionary: {'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib': 0, 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa': 1, 'normal': 2, 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa': 3}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the list of class names and the dictionary mapping class names to their indices\n",
    "class_names = train_data.classes\n",
    "class_dict = train_data.class_to_idx\n",
    "\n",
    "# Output the class names and the class dictionary\n",
    "print(\"Class Names:\", class_names)\n",
    "print(\"Class Dictionary:\", class_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68593008-e48f-4bd4-b6d4-c8480ed83ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': 2, 'adenocarcinoma_left.lower.lobe': 0, 'large.cell.carcinoma_left.hilum': 1, 'squamous.cell.carcinoma_left.hilum': 3} 4\n"
     ]
    }
   ],
   "source": [
    "# Key mapping from old to new\n",
    "key_updates = {\n",
    "    'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib': 'adenocarcinoma_left.lower.lobe',\n",
    "    'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa': 'large.cell.carcinoma_left.hilum',\n",
    "    'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa': 'squamous.cell.carcinoma_left.hilum'\n",
    "}\n",
    "\n",
    "# Update the dictionary\n",
    "for old_key, new_key in key_updates.items():\n",
    "    if old_key in class_dict:\n",
    "        class_dict[new_key] = class_dict.pop(old_key)\n",
    "\n",
    "# Define new keys corresponding to their simplified names\n",
    "new_key1 = 'adenocarcinoma_left.lower.lobe'\n",
    "new_key2 = 'large.cell.carcinoma_left.hilum'\n",
    "new_key3 = 'squamous.cell.carcinoma_left.hilum'\n",
    "\n",
    "# Update specific indices in the class_names list\n",
    "class_names[0] = new_key1\n",
    "class_names[1] = new_key2\n",
    "class_names[3] = new_key3 \n",
    "\n",
    "print(class_dict, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "844711ae-8025-4191-aec2-f52ac2ddfb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (1): Dropout(p=0.2, inplace=False)\n",
       "  (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (3): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the model\n",
    "resnet18_model.fc = nn.Sequential (\n",
    "    nn.Linear(512,512),\n",
    "    nn.Dropout(0.2),\n",
    "     nn.Linear(512,256),\n",
    "    nn.Linear(256,len(class_names)), # -> len(labels) labels according to labels\n",
    ")\n",
    "resnet18_model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15830e5d-1003-4fe2-b5f8-9b609f2a902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_model.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30890b64-cbcf-4b93-87ab-10955aff3313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 4]                    --\n",
       "├─Conv2d: 1-1                            [1, 64, 32, 32]           9,408\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 32, 32]           128\n",
       "├─ReLU: 1-3                              [1, 64, 32, 32]           --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 16, 16]           --\n",
       "├─Sequential: 1-5                        [1, 64, 16, 16]           --\n",
       "│    └─BasicBlock: 2-1                   [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 16, 16]           36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 16, 16]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 16, 16]           --\n",
       "│    └─BasicBlock: 2-2                   [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 64, 16, 16]           36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-9                    [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 16, 16]           36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-12                   [1, 64, 16, 16]           --\n",
       "├─Sequential: 1-6                        [1, 128, 8, 8]            --\n",
       "│    └─BasicBlock: 2-3                   [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-13                 [1, 128, 8, 8]            73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 128, 8, 8]            256\n",
       "│    │    └─ReLU: 3-15                   [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-16                 [1, 128, 8, 8]            147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 128, 8, 8]            256\n",
       "│    │    └─Sequential: 3-18             [1, 128, 8, 8]            8,448\n",
       "│    │    └─ReLU: 3-19                   [1, 128, 8, 8]            --\n",
       "│    └─BasicBlock: 2-4                   [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-20                 [1, 128, 8, 8]            147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [1, 128, 8, 8]            256\n",
       "│    │    └─ReLU: 3-22                   [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-23                 [1, 128, 8, 8]            147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [1, 128, 8, 8]            256\n",
       "│    │    └─ReLU: 3-25                   [1, 128, 8, 8]            --\n",
       "├─Sequential: 1-7                        [1, 256, 4, 4]            --\n",
       "│    └─BasicBlock: 2-5                   [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-26                 [1, 256, 4, 4]            294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 256, 4, 4]            512\n",
       "│    │    └─ReLU: 3-28                   [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-29                 [1, 256, 4, 4]            589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 256, 4, 4]            512\n",
       "│    │    └─Sequential: 3-31             [1, 256, 4, 4]            33,280\n",
       "│    │    └─ReLU: 3-32                   [1, 256, 4, 4]            --\n",
       "│    └─BasicBlock: 2-6                   [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-33                 [1, 256, 4, 4]            589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [1, 256, 4, 4]            512\n",
       "│    │    └─ReLU: 3-35                   [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-36                 [1, 256, 4, 4]            589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [1, 256, 4, 4]            512\n",
       "│    │    └─ReLU: 3-38                   [1, 256, 4, 4]            --\n",
       "├─Sequential: 1-8                        [1, 512, 2, 2]            --\n",
       "│    └─BasicBlock: 2-7                   [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-39                 [1, 512, 2, 2]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 512, 2, 2]            1,024\n",
       "│    │    └─ReLU: 3-41                   [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-42                 [1, 512, 2, 2]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [1, 512, 2, 2]            1,024\n",
       "│    │    └─Sequential: 3-44             [1, 512, 2, 2]            132,096\n",
       "│    │    └─ReLU: 3-45                   [1, 512, 2, 2]            --\n",
       "│    └─BasicBlock: 2-8                   [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-46                 [1, 512, 2, 2]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [1, 512, 2, 2]            1,024\n",
       "│    │    └─ReLU: 3-48                   [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-49                 [1, 512, 2, 2]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [1, 512, 2, 2]            1,024\n",
       "│    │    └─ReLU: 3-51                   [1, 512, 2, 2]            --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
       "├─Sequential: 1-10                       [1, 4]                    --\n",
       "│    └─Linear: 2-9                       [1, 512]                  262,656\n",
       "│    └─Dropout: 2-10                     [1, 512]                  --\n",
       "│    └─Linear: 2-11                      [1, 256]                  131,328\n",
       "│    └─Linear: 2-12                      [1, 4]                    1,028\n",
       "==========================================================================================\n",
       "Total params: 11,571,524\n",
       "Trainable params: 11,571,524\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 148.45\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 3.25\n",
       "Params size (MB): 46.29\n",
       "Estimated Total Size (MB): 49.59\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet18_model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.SGD(resnet18_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "summary(resnet18_model, input_size=[1, 3, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b6b0b20-f0c0-4b34-a92b-5a330c53b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer:torch.optim.Optimizer,\n",
    "               device=device):\n",
    "  model.train()\n",
    "\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    y_pred = model(X) \n",
    "\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss.item()\n",
    "\n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "  \n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracy metric\n",
    "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "    train_acc += (y_pred_class==y).sum().item()/len(y_pred)\n",
    "  \n",
    "  # Adjust metrics to get average loss and accuracy per batch\n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader) \n",
    "  return train_loss, train_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed5e3440-f599-475e-93d9-02f98a6aba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device=device):\n",
    "  model.eval()\n",
    "\n",
    "  test_loss, test_acc = 0,  0\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X, y) in enumerate(dataloader): \n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      test_pred_logits = model(X)\n",
    "\n",
    "     \n",
    "      loss = loss_fn(test_pred_logits, y)\n",
    "      test_loss += loss.item()\n",
    "\n",
    "    \n",
    "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch\n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df928df7-1d6c-42b3-b362-2a2339b8ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader,\n",
    "          test_dataloader,\n",
    "          optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5, \n",
    "          device=device):\n",
    "  \n",
    "  results = {\"train_loss\": [],\n",
    "             \"train_acc\": [],\n",
    "             \"test_loss\": [],\n",
    "             \"test_acc\": []}\n",
    "  \n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(model=model,\n",
    "                                       dataloader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       device=device)\n",
    "    test_loss, test_acc = test_step(model=model,\n",
    "                                    dataloader=test_dataloader,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    device=device)\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
    "\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_acc\"].append(train_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_acc\"].append(test_acc)\n",
    "  \n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb2b42ff-8eb5-47a5-a276-69c28832ecba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477cba5f769a430ab80aa0f093362432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.9256 | Train acc: 0.6134 | Test loss: 1.9359 | Test acc: 0.4062\n",
      "Epoch: 1 | Train loss: 0.7320 | Train acc: 0.7706 | Test loss: 1.9163 | Test acc: 0.5312\n",
      "Epoch: 2 | Train loss: 0.5658 | Train acc: 0.7800 | Test loss: 1.2438 | Test acc: 0.6771\n",
      "Epoch: 3 | Train loss: 0.2259 | Train acc: 0.9250 | Test loss: 0.6922 | Test acc: 0.7812\n",
      "Epoch: 4 | Train loss: 0.1023 | Train acc: 0.9703 | Test loss: 1.7482 | Test acc: 0.6354\n",
      "Epoch: 5 | Train loss: 0.1832 | Train acc: 0.9453 | Test loss: 0.4907 | Test acc: 0.8750\n",
      "Epoch: 6 | Train loss: 0.1104 | Train acc: 0.9563 | Test loss: 0.5751 | Test acc: 0.8542\n",
      "Epoch: 7 | Train loss: 0.1418 | Train acc: 0.9472 | Test loss: 0.6214 | Test acc: 0.7708\n",
      "Epoch: 8 | Train loss: 0.3904 | Train acc: 0.8962 | Test loss: 0.8450 | Test acc: 0.7396\n",
      "Epoch: 9 | Train loss: 0.3273 | Train acc: 0.9019 | Test loss: 0.5814 | Test acc: 0.8333\n",
      "Epoch: 10 | Train loss: 0.3001 | Train acc: 0.8988 | Test loss: 0.5385 | Test acc: 0.8646\n",
      "Epoch: 11 | Train loss: 0.2106 | Train acc: 0.9197 | Test loss: 0.7886 | Test acc: 0.7812\n",
      "Epoch: 12 | Train loss: 0.0926 | Train acc: 0.9672 | Test loss: 0.4965 | Test acc: 0.8438\n",
      "Epoch: 13 | Train loss: 0.0447 | Train acc: 0.9806 | Test loss: 0.5570 | Test acc: 0.8854\n",
      "Epoch: 14 | Train loss: 0.1153 | Train acc: 0.9672 | Test loss: 0.9365 | Test acc: 0.6979\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 15\n",
    "\n",
    "model_0_results = train(model=resnet18_model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95910a87-1d38-47c1-8e42-9ac35d86a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet18_model.state_dict(), \"../models/ct_scan_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
